{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0000001",
   "metadata": {},
   "source": [
    "# PII Detection & Data Quality Validation Pipeline\n",
    "\n",
    "This notebook demonstrates an end-to-end **fintech data quality pipeline** that ingests raw customer data, audits it for quality issues, detects and masks Personally Identifiable Information (PII), and produces a clean, GDPR-compliant dataset.\n",
    "\n",
    "### Pipeline Stages\n",
    "| Stage | Module | Purpose |\n",
    "|-------|--------|---------|\n",
    "| **Part 1** | `DataProfiler` | Profile data quality — completeness, types, formatting issues |\n",
    "| **Part 2** | `PIIDetector` | Scan for PII using regex and heuristic matching |\n",
    "| **Part 3** | `FintechGXValidator` | Validate schema rules with Great Expectations |\n",
    "| **Part 4** | `DataRemediator` | Clean and normalize data to pass validation |\n",
    "| **Part 5** | `DataMasker` | Mask all PII fields for safe downstream use |\n",
    "\n",
    "### Input / Output\n",
    "- **Input:** `data/raw/customers_raw.csv` — 10 customer records with deliberate quality issues\n",
    "- **Output:** `data/processed/customers_masked.csv` — cleaned and masked dataset\n",
    "- **Reports:** Quality profile, PII detection, validation results, cleaning log, masked sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca4faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pipeline Logger initialized. Ready for Data Quality Analysis.\n",
      "INFO: Data directory verified.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "input_path = PROJECT_ROOT + '/data/raw/customers_raw.csv'\n",
    "\n",
    "#part 1: Data Profiler\n",
    "from src.part1.data_profiler import DataProfiler\n",
    "from src.utils.logger_config import setup_pipeline_logger\n",
    "\n",
    "#part 2: PII Detector\n",
    "from src.part2.pii_detector import PIIDetector\n",
    "\n",
    "#part 3: Data Validator\n",
    "from src.part3.data_validator import FintechGXValidator\n",
    "\n",
    "#part 4: Data Remediator\n",
    "from src.part4.cleaning import DataRemediator\n",
    "\n",
    "#part 5: Data Masker\n",
    "from src.part5.data_masker import DataMasker\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize our specialized logger\n",
    "logger = setup_pipeline_logger()\n",
    "\n",
    "logger.info(\"Pipeline Logger initialized. Ready for Data Quality Analysis.\")\n",
    "\n",
    "# Verify the data directory exists\n",
    "if not os.path.exists('../data'):\n",
    "    logger.error(\"Data directory not found!\")\n",
    "else:\n",
    "    logger.info(\"Data directory verified.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda8dd4f",
   "metadata": {},
   "source": [
    "## Part 1: Data Profiling & Quality Assessment\n",
    "This stage loads the raw customer dataset and performs a comprehensive data quality audit. The `DataProfiler` checks for:\n",
    "- **Completeness** — missing values and sentinel placeholders (e.g., `invalid_date`)\n",
    "- **Data Types** — verifying each column matches expected types (INT, STRING, DATE, NUMERIC)\n",
    "- **Quality Issues** — inconsistent phone formats, invalid category values, duplicate IDs\n",
    "\n",
    "The output is a structured text report saved to `data/reports/data_quality_report.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6cbcd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Loaded 10 rows from customers_raw.csv\n",
      "WARNING: Formatting issue: 2 rows have inconsistent phone formats.\n",
      "INFO: Analysis complete. Report saved to: ../data/reports/data_quality_report.txt\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and run\n",
    "profiler = DataProfiler(input_path=input_path)\n",
    "profiler.run_full_analysis(output_report_path='../data/reports/data_quality_report.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42ee95",
   "metadata": {},
   "source": [
    "## Part 2: PII Detection & Risk Assessment\n",
    "This stage scans the dataset for **Personally Identifiable Information (PII)** using regex pattern matching and heuristic checks. The `PIIDetector` identifies:\n",
    "- **Emails** — matched via RFC-style regex patterns\n",
    "- **Phone Numbers** — matched via flexible digit/separator patterns\n",
    "- **Addresses** — detected by non-null entries with sufficient length\n",
    "- **Dates of Birth** — validated as present and non-sentinel values\n",
    "\n",
    "The scan produces a risk assessment report with exposure analysis and mitigation recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0531d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Starting PII scanning process...\n",
      "INFO: Scan complete. Found 10 emails and 10 phone numbers.\n",
      "INFO: PII Detection Report saved to ../data/reports/pii_detection_report.txt\n",
      "\n",
      "PII Scan Summary:\n",
      "Emails found: 10\n",
      "Phones found: 10\n"
     ]
    }
   ],
   "source": [
    "detector = PIIDetector(profiler.df)\n",
    "\n",
    "# Run the scan and generate report\n",
    "detector.scan_pii().generate_report('../data/reports/pii_detection_report.txt')\n",
    "\n",
    "# Quick visual check in the notebook\n",
    "print(\"\\nPII Scan Summary:\")\n",
    "print(f\"Emails found: {detector.risk_results['emails']}\")\n",
    "print(f\"Phones found: {detector.risk_results['phones']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f63d685",
   "metadata": {},
   "source": [
    "## Part 3: Schema Validation with Great Expectations\n",
    "This stage applies formal schema validation using **Great Expectations (GX 1.x)**. The `FintechGXValidator` enforces strict rules on the raw data:\n",
    "- `customer_id` must be unique, positive, and non-null\n",
    "- Names must be non-null, 2–50 characters, alphabetic only\n",
    "- `income` must be numeric and within a realistic range (0–10M)\n",
    "- `account_status` must be one of: `active`, `inactive`, `suspended`\n",
    "- Dates must conform to `YYYY-MM-DD` format\n",
    "\n",
    "The validation result (True/False) shows whether the raw data passes all business rules. Failures are expected at this stage — they will be remediated in Part 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0acee2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Building Strict Expectations for suite: fintech_suite\n",
      "INFO: Starting GX 1.x Validation execution...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482a9cefc46344c9b7d7f922b76b841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Forensic GX Report saved to ../data/reports/validation_results.txt\n",
      "Validation Success: False\n"
     ]
    }
   ],
   "source": [
    "# Initialize with the modern API\n",
    "gx_engine = FintechGXValidator(profiler.df)\n",
    "\n",
    "# Build, Validate, and Generate the deliverable\n",
    "results = gx_engine.build_expectations().validate(\n",
    "    report_path='../data/reports/validation_results.txt'\n",
    ")\n",
    "\n",
    "print(f\"Validation Success: {results.success}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4062c65e",
   "metadata": {},
   "source": [
    "## Part 4: Data Cleaning & Remediation\n",
    "This stage applies automated fixes to resolve the quality issues identified in Parts 1 and 3. The `DataRemediator` performs:\n",
    "- **Name Normalization** — applies title case to `first_name` and `last_name`\n",
    "- **Phone Standardization** — converts all formats (dotted, parenthesized, continuous digits) to `XXX-XXX-XXXX`\n",
    "- **Date Normalization** — converts all date formats to `YYYY-MM-DD` and replaces `invalid_date` sentinels with NaT\n",
    "- **Missing Value Imputation** — fills nulls with safe defaults (`[UNKNOWN]`, `0`, `unknown`)\n",
    "\n",
    "After cleaning, a **re-validation** is run with Great Expectations to confirm the fixes. The cleaning log with before/after statistics is saved to `data/reports/cleaning_log.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b584e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Building Strict Expectations for suite: cleaned_suite\n",
      "INFO: Starting GX 1.x Validation execution...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304698115daa4e8b9ddde2e963d2b288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Forensic GX Report saved to ../data/reports/validation_final.txt\n",
      "INFO: Cleaning log saved to ../data/reports/cleaning_log.txt\n",
      "INFO: Pipeline Execution Complete. Golden Dataset generated.\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize Remediator\n",
    "remediator = DataRemediator(profiler.df)\n",
    "\n",
    "# 2. Execute Cleaning Pipeline\n",
    "remediator.normalize_names().normalize_phones().normalize_dates().handle_missing()\n",
    "\n",
    "# 3. Re-Validate to confirm 0 failures\n",
    "gx_engine_v2 = FintechGXValidator(remediator.df, suite_name=\"cleaned_suite\")\n",
    "results_after = gx_engine_v2.build_expectations().validate(report_path='../data/reports/validation_final.txt')\n",
    "\n",
    "# 4. Generate the Log\n",
    "remediator.generate_log(\n",
    "    output_path='../data/reports/cleaning_log.txt',\n",
    "    validation_before=7, # Based on our previous Part 3 findings\n",
    "    validation_after=results_after.statistics['unsuccessful_expectations']\n",
    ")\n",
    "\n",
    "# 5. Save final CSV\n",
    "remediator.df.to_csv('../data/processed/customers_cleaned.csv', index=False)\n",
    "logger.info(\"Pipeline Execution Complete. Golden Dataset generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879acc2",
   "metadata": {},
   "source": [
    "## Part 5: PII Masking & GDPR Compliance\n",
    "This final stage masks all PII fields to produce a **GDPR-compliant** dataset safe for analytics teams. The `DataMasker` applies:\n",
    "- **Names** — `John Doe` → `J*** D***`\n",
    "- **Emails** — `john.doe@gmail.com` → `j***@gmail.com`\n",
    "- **Phones** — `555-123-4567` → `***-***-4567`\n",
    "- **Addresses** — replaced with `[MASKED ADDRESS]`\n",
    "- **Dates of Birth** — `1985-03-15` → `1985-**-**`\n",
    "\n",
    "Business-critical fields (income, account status, created date) remain intact. The masked dataset is saved to `data/processed/customers_masked.csv`, along with a before/after comparison report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f1bfdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Masked dataset saved to ../data/processed/customers_masked.csv\n",
      "INFO: Masked sample report generated at ../data/reports/masked_sample.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>account_status</th>\n",
       "      <th>created_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>J***</td>\n",
       "      <td>D***</td>\n",
       "      <td>j***@gmail.com</td>\n",
       "      <td>***-***-4567</td>\n",
       "      <td>1985-**-**</td>\n",
       "      <td>[MASKED ADDRESS]</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>active</td>\n",
       "      <td>2024-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>J***</td>\n",
       "      <td>S***</td>\n",
       "      <td>j***@company.com</td>\n",
       "      <td>***-***-6543</td>\n",
       "      <td>1990-**-**</td>\n",
       "      <td>[MASKED ADDRESS]</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>active</td>\n",
       "      <td>2024-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>N***</td>\n",
       "      <td>J***</td>\n",
       "      <td>b***@email.com</td>\n",
       "      <td>***-***-5678</td>\n",
       "      <td>1988-**-**</td>\n",
       "      <td>[MASKED ADDRESS]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>suspended</td>\n",
       "      <td>2024-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M***</td>\n",
       "      <td>B***</td>\n",
       "      <td>m***@gmail.com</td>\n",
       "      <td>***-***-6789</td>\n",
       "      <td>UNKN-**-**</td>\n",
       "      <td>[MASKED ADDRESS]</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>2024-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>R***</td>\n",
       "      <td>N***</td>\n",
       "      <td>r***@yahoo.com</td>\n",
       "      <td>***-***-7890</td>\n",
       "      <td>2005-**-**</td>\n",
       "      <td>[MASKED ADDRESS]</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>active</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id first_name last_name             email         phone  \\\n",
       "0            1       J***      D***    j***@gmail.com  ***-***-4567   \n",
       "1            2       J***      S***  j***@company.com  ***-***-6543   \n",
       "2            3       N***      J***    b***@email.com  ***-***-5678   \n",
       "3            4       M***      B***    m***@gmail.com  ***-***-6789   \n",
       "4            5       R***      N***    r***@yahoo.com  ***-***-7890   \n",
       "\n",
       "  date_of_birth           address    income account_status created_date  \n",
       "0    1985-**-**  [MASKED ADDRESS]   75000.0         active   2024-01-10  \n",
       "1    1990-**-**  [MASKED ADDRESS]   95000.0         active   2024-01-11  \n",
       "2    1988-**-**  [MASKED ADDRESS]       0.0      suspended   2024-01-12  \n",
       "3    UNKN-**-**  [MASKED ADDRESS]  120000.0        unknown   2024-01-13  \n",
       "4    2005-**-**  [MASKED ADDRESS]   55000.0         active      UNKNOWN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Initialize Masker with the cleaned data from Part 4\n",
    "masker = DataMasker(remediator.df)\n",
    "\n",
    "# 2. Execute Masking Chain\n",
    "masker.mask_names().mask_emails().mask_phones().mask_addresses().mask_dob()\n",
    "\n",
    "# 3. Save the final GDPR-compliant file\n",
    "masked_df = masker.save_masked_data('../data/processed/customers_masked.csv')\n",
    "\n",
    "# 4. Generate the deliverable comparison\n",
    "masker.generate_masked_sample(profiler.df, '../data/reports/masked_sample.txt')\n",
    "\n",
    "display(masked_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z9999999",
   "metadata": {},
   "source": [
    "---\n",
    "##  Pipeline Complete\n",
    "\n",
    "All five stages have executed successfully. The following deliverables have been generated:\n",
    "\n",
    "| Deliverable | Location |\n",
    "|-------------|----------|\n",
    "| Data Quality Profile | `data/reports/data_quality_report.txt` |\n",
    "| PII Detection Report | `data/reports/pii_detection_report.txt` |\n",
    "| Validation Results (Raw) | `data/reports/validation_results.txt` |\n",
    "| Validation Results (Cleaned) | `data/reports/validation_final.txt` |\n",
    "| Cleaning Log | `data/reports/cleaning_log.txt` |\n",
    "| Masked Sample Comparison | `data/reports/masked_sample.txt` |\n",
    "| Cleaned Dataset | `data/processed/customers_cleaned.csv` |\n",
    "| Masked Dataset (Final) | `data/processed/customers_masked.csv` |\n",
    "\n",
    "The masked dataset is safe for sharing with analytics teams — all PII has been obfuscated while preserving business-critical fields like income, account status, and dates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
